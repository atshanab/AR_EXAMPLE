<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover" />
  <title>AR_EXAMPLE â€” Face Filter (Minimal)</title>
  <style>
    html, body { margin:0; padding:0; height:100%; overflow:hidden; background:#000; }
    #stage { position:fixed; inset:0; }
    video, canvas { position:absolute; top:0; left:0; width:100%; height:100%; object-fit:cover; transform: scaleX(-1); }
    #ui { position:fixed; inset:0; display:flex; align-items:center; justify-content:center; color:#fff; background:#000; z-index:10; }
    #ui.hide { display:none; }
    button { padding:12px 16px; border-radius:12px; border:0; background:#1f6feb; color:#fff; font-size:16px; }
    #log { position:fixed; left:8px; top:8px; color:#0f0; font:12px ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; z-index:20; white-space:pre-wrap; max-width:90vw; }
    .wm { position:fixed; right:8px; bottom:8px; color:#fff9; font:12px ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3/camera_utils.js"></script>
</head>
<body>
  <div id="ui"><div><h2>Face Filter</h2><p>Tap Start and allow camera.</p><button id="start">Start</button></div></div>
  <div id="log"></div>
  <div class="wm">AR_EXAMPLE</div>
  <div id="stage">
    <video id="video" playsinline muted></video>
    <canvas id="canvas"></canvas>
  </div>

<script>
const logEl = document.getElementById('log');
function log(s){ logEl.textContent = String(s); }

const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');

function fit(){ canvas.width = stage.clientWidth; canvas.height = stage.clientHeight; }
const stage = document.getElementById('stage'); window.addEventListener('resize', fit);

function drawGlasses(lm) {
  const W = canvas.width, H = canvas.height;
  const toXY = p => ({ x: (1 - p.x) * W, y: p.y * H });

  const L = toXY(lm[263]), LI = toXY(lm[362]);
  const R = toXY(lm[33]),  RI = toXY(lm[133]);
  const leftC = { x:(L.x+LI.x)/2, y:(L.y+LI.y)/2 };
  const rightC= { x:(R.x+RI.x)/2, y:(R.y+RI.y)/2 };
  const dx = leftC.x - rightC.x, dy = leftC.y - rightC.y;
  const angle = Math.atan2(dy, dx);
  const eyeDist = Math.hypot(dx, dy);
  const lensW = eyeDist * 0.55, lensH = eyeDist * 0.32, bridgeW = eyeDist * 0.18;
  const rim = Math.max(2, Math.round(lensH * 0.12));
  const mid = { x:(leftC.x+rightC.x)/2, y:(leftC.y+rightC.y)/2 };
  const halfGap = bridgeW/2, lensGap = halfGap + lensW/2;

  ctx.save();
  ctx.translate(mid.x, mid.y);
  ctx.rotate(angle);

  ctx.fillStyle = 'rgba(15,15,15,0.94)';
  const rr = lensH*0.25;
  function rrRect(x,y,w,h){ const r=Math.min(rr, w/2, h/2); ctx.beginPath();
    ctx.moveTo(x+r,y); ctx.arcTo(x+w,y,x+w,y+h,r); ctx.arcTo(x+w,y+h,x,y+h,r);
    ctx.arcTo(x,y+h,x,y,r); ctx.arcTo(x,y,x+w,y,r); ctx.closePath(); ctx.fill(); }

  rrRect(-lensGap - lensW/2, -lensH/2, lensW, lensH);
  rrRect(lensGap - lensW/2, -lensH/2, lensW, lensH);

  ctx.fillStyle='rgba(20,20,20,0.95)';
  rrRect(-halfGap, -lensH*0.18, bridgeW, lensH*0.36);

  ctx.strokeStyle='rgba(10,10,10,0.9)';
  ctx.lineWidth=Math.max(2, rim*0.6);
  const armLen=lensW*0.9;
  ctx.beginPath();
  ctx.moveTo(-lensGap - lensW/2, -lensH*0.15); ctx.lineTo(-lensGap - lensW/2 - armLen, -lensH*0.15);
  ctx.moveTo(lensGap + lensW/2, -lensH*0.15); ctx.lineTo(lensGap + lensW/2 + armLen, -lensH*0.15);
  ctx.stroke();

  ctx.restore();
}

async function start() {
  try {
    document.getElementById('ui').classList.add('hide');
    fit();
    log('requesting camera...');
    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio:false });
    video.srcObject = stream;
    await video.play();
    log('camera started');

    const faceMesh = new FaceMesh.FaceMesh({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh@0.4/${file}`
    });
    faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });

    const camera = new Camera.Camera(video, {
      onFrame: async () => { await faceMesh.send({image: video}); },
      width: 1280, height: 720
    });
    camera.start();

    faceMesh.onResults((results) => {
      ctx.clearRect(0,0,canvas.width,canvas.height);
      if (!results.multiFaceLandmarks || results.multiFaceLandmarks.length===0){ log('no face'); return; }
      drawGlasses(results.multiFaceLandmarks[0]);
      log('');
    });
  } catch (e) {
    log('error: ' + e.message);
    alert('Camera error: ' + e.message);
  }
}

document.getElementById('start').addEventListener('click', start);
</script>
</body>
</html>
